#C:\Users\PROGRESA HUACHIPA\OneDrive\Escritorio\BISem12\BuenaAventura\SVR.py
# -*- coding: utf-8 -*-
"""Eq.D_Buenaventura

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TwldTMHFwQpVQarDqC2pmdoZsCe54Vvr

# IMPORTING LIBRARIES
"""

# Basicos
import pandas as pd # Manipulación y análisis de datos
import numpy as np # Operaciones numéricas y algebra lineal

import plotly.graph_objects as go
import plotly.express as px


# Extraer información del instrumento financiero
import yfinance as yf # Descarga de datos financieros desde Yahoo Finance

# Preprocesamiento
from sklearn.model_selection import train_test_split # División de los datos en conjuntos de entrenamiento y prueba
from sklearn.preprocessing import StandardScaler # Escalado de características
from sklearn.preprocessing import MinMaxScaler # Escalado de características a un rango específico
from statsmodels.tsa.seasonal import seasonal_decompose # Descomposición de series temporales

# Evaluacion
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error # Métricas de evaluación

# Visualizaciones
import matplotlib.pyplot as plt # Generación de gráficos y visualizaciones
import seaborn as sns # Visualización de datos estadísticos

# RNN: LSTM
from tensorflow.keras.models import Sequential # Creación de modelos secuenciales de Keras
from tensorflow.keras.layers import LSTM, Dense # Capas LSTM y densas para redes neuronales

# Support Vector Regressor
from sklearn.model_selection import GridSearchCV # Búsqueda en cuadrícula para optimización de hiperparámetros
from sklearn.svm import SVR # Soporte vectorial para regresión
from sklearn.pipeline import Pipeline # Creación de pipelines para flujos de trabajo de ML

# ANN: MLP Regressor
from sklearn.neural_network import MLPRegressor # Regressor de perceptrón multicapa

# Modelo Híbrido
from sklearn.kernel_approximation import RBFSampler # Aproximación de kernel de base radial (RBF)
from sklearn.linear_model import Ridge # Regresión Ridge
from sklearn.pipeline import make_pipeline # Creación de pipelines para flujos de trabajo de ML

from ModelosPrediccion.extraccion_datos import extraccion_datos

import plotly.graph_objects as go


"""# COMPAÑIA DE MINAS BUENAVENURA SAA (BVN)

## Extracción de datos
"""
def ejecutar_svr(df,instrumento_financiero, fecha_inicio, fecha_fin):
    bvn_df, fig1, fig2, fig3, fig4 = extraccion_datos(df,instrumento_financiero, fecha_inicio, fecha_fin)


    """## MODELO: Support Vector Regressor"""

    # Seleccionar las columnas que quieres usar como input para el modelo LSTM
    features = [ 'Precio Anterior', 'Precio Máximo Anterior', 'Precio Mínimo Anterior', 'Precio Apertura Anterior',
                    'PM_10', 'Middle Band Bollinger', 'Upper Band Bollinger',
                    'Lower Band Bollinger', 'Precio Plata']

    X=bvn_df[features]
    y=bvn_df['Close']

    # División de los datos en conjuntos de entrenamiento y prueba
    split = int(0.8 * len(bvn_df))
    X_train, X_test = X[:split], X[split:]
    y_train, y_test = y[:split], y[split:]

    """### Definición de los parámetros del modelo y predicción"""

    # Definición de los parámetros para GridSearchCV
    param_grid = {
        'svr__kernel': ['poly'],
        'svr__degree': [1, 2],
        'svr__C': [2**-1, 1, 2, 3, 10, 20, 100]
    }

    # Crear un pipeline que incluya la estandarización y el modelo SVR
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('svr', SVR())
    ])

    # Configurar GridSearchCV
    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', error_score='raise')

    # Entrenar el modelo
    grid_search.fit(X_train, y_train)

    # Obtener los mejores parámetros
    best_params = grid_search.best_params_
    best_model = grid_search.best_estimator_

    # Mostrar los mejores parámetros
    print("Mejores parámetros:", best_params)

    # Realizar predicciones con el conjunto de prueba
    y_pred = best_model.predict(X_test)

    # Asumimos que ya tienes y_test y y_pred de las celdas anteriores

    # Crear un DataFrame con las fechas y los valores de prueba y predicciones
    result_df = pd.DataFrame({'Fecha': X_test.index, 'Valores Reales': y_test, 'Predicciones': y_pred})

    # Graficar las predicciones vs los valores reales
    fig5 = go.Figure()

    # Añadir la línea de Valores Reales
    fig5.add_trace(go.Scatter(
        x=result_df['Fecha'],
        y=result_df['Valores Reales'],
        mode='lines',
        name='Valores Reales'
    ))

    # Añadir la línea de Predicciones
    fig5.add_trace(go.Scatter(
        x=result_df['Fecha'],
        y=result_df['Predicciones'],
        mode='lines',
        name='Predicciones',
        line=dict(color='red', dash='dash')
    ))

    # Configurar el diseño de la figura
    fig5.update_layout(
        title='Comparación de Predicciones y Valores Reales',
        xaxis_title='Fecha',
        yaxis_title='Precio de Cierre',
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        template='plotly_white'
    )

    # Rotar las etiquetas del eje x para mejor visualización
    fig5.update_xaxes(tickangle=45)

    """### Evaluación del modelo"""

    # Calcular métricas de evaluación
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mape = np.mean((np.abs(y_test - y_pred) / y_test)) * 100

    # Calcular los errores
    errors = result_df['Valores Reales'] - result_df['Predicciones']

    # Graficar la distribución de los errores
    plt.figure(figsize=(10, 6))
    sns.histplot(errors, kde=True, bins=30, color='blue')
    plt.title('Distribución de los Errores')
    plt.xlabel('Error')
    plt.ylabel('Frecuencia')
    plt.grid(True)
    fig6 = plt.gcf()

    return mse , rmse , mape, fig1, fig2, fig3, fig4, fig5,fig6 
